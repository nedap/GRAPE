{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/toy-problem/notebooks\n",
      "Changing directory\n",
      "New Working directory: /srv/healthcare/datascience/data/part-net/data_knife\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Use pathlib\n",
    "current_dir = Path.cwd()\n",
    "target_dir = Path('/srv/healthcare/datascience/data/part-net/data_knife/')\n",
    "\n",
    "print(f'Current Working Directory: {current_dir}')\n",
    "if current_dir != target_dir:\n",
    "    print('Changing directory')\n",
    "    os.chdir(target_dir)\n",
    "    print(f'New Working directory: {Path.cwd()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Table dataset contains some small \"weird\" samples, such as pool table, I would like to only keep the \"regular_tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing /srv/healthcare/datascience/data/part-net/data_knife/1056\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/2018\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/1051\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/2009\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/212\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/697\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/2015\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/224\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/114\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/397\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/567\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/421\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/924\n",
      "removing /srv/healthcare/datascience/data/part-net/data_knife/1213\n",
      "14 removed\n"
     ]
    }
   ],
   "source": [
    "# only keep \"regular_table\"\n",
    "import shutil\n",
    "def check_occurrence(data, keyword):\n",
    "    \"\"\"\n",
    "    Checks if a keyword occurs in the nested data structure.\n",
    "\n",
    "    :param data: List of dictionaries representing JSON data.\n",
    "    :param keyword: String to search for in the data.\n",
    "    :return: Boolean indicating whether the keyword was found.\n",
    "    \"\"\"\n",
    "    def search(items):\n",
    "        for item in items:\n",
    "            if keyword in item.values():\n",
    "                return True\n",
    "            if 'children' in item:\n",
    "                if search(item['children']):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    return search(data)\n",
    "\n",
    "def remove(results):\n",
    "     \"\"\"\n",
    "     Samples containing these keys in their results.json we want to remove. \n",
    "     \"\"\"\n",
    "     if check_occurrence(results, \"fingerhole\"):\n",
    "          return True\n",
    "    #  if check_occurrence(results, \"picnic_table\"):\n",
    "    #       return True\n",
    "    #  if check_occurrence(results, \"game_table\"):\n",
    "    #       return True\n",
    "    #  if not check_occurrence(results, \"regular_table\"):\n",
    "    #       return True\n",
    "    #  if check_occurrence(results, \"other_leaf\"):\n",
    "    #       return True\n",
    "     \n",
    "     return False\n",
    "\n",
    "cnt = 0\n",
    "for subdirectory in target_dir.iterdir():\n",
    "    with open(subdirectory / 'result.json', 'r') as file:\n",
    "                results = json.load(file)\n",
    "    # we only want to keep regular tables. \n",
    "    if remove(results): \n",
    "        cnt += 1\n",
    "        print(\"removing\", subdirectory)\n",
    "        shutil.rmtree(subdirectory)         \n",
    "print(f'{cnt} removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the unique lables from the tables dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 12 unique labels\n",
      "['knife', 'bolster', 'cutting_instrument', 'butt', 'handle', 'handle_side', 'blade', 'guard', 'other_leaf', 'blade_side', 'dagger', 'other']\n",
      "8\n",
      "['bolster', 'butt', 'handle', 'handle_side', 'blade', 'guard', 'blade_side', 'miscellaneous']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_labels(data):\n",
    "    \"\"\"\n",
    "    Extracts unique labels from the JSON data.\n",
    "\n",
    "    :param data: List of dictionaries representing JSON data.\n",
    "    :return: Set of unique labels.\n",
    "    \"\"\"\n",
    "    labels = set()\n",
    "\n",
    "    def extract(items):\n",
    "        for item in items:\n",
    "            if 'name' in item:\n",
    "                labels.add(item['name'])\n",
    "            if 'children' in item:\n",
    "                extract(item['children'])\n",
    "\n",
    "    extract(data)\n",
    "    return labels\n",
    "\n",
    "unique_labels = set()\n",
    "for subdirectory in target_dir.iterdir():\n",
    "    if not subdirectory.is_dir():\n",
    "            continue  # Skip if it's not a directory\n",
    "    with open(subdirectory / 'result.json', 'r') as file:\n",
    "        results_after_merging_data = json.load(file)\n",
    "    unique_labels.update(extract_labels(results_after_merging_data))\n",
    "    \n",
    "print(f'found {len(unique_labels)} unique labels')\n",
    "print(list(unique_labels))\n",
    "\n",
    "# these are the labels we want to keep for the TABLE dataset\n",
    "# to_keep_table = ['board', 'leg', 'glass', 'tabletop_connector', 'bar', 'shelf', 'vertical_side_panel', 'bar_stretcher', 'bottom_panel', 'other_leaf', 'pedestal', 'central_support', 'back_panel', 'runner', 'drawer_front', 'circle', 'vertical_front_panel', 'vertical_divider_panel', 'foot', 'drawer_bottom', 'cabinet_door_surface', 'drawer_side']\n",
    "to_keep_table = ['guard', 'bolster', 'butt', 'blade', 'handle_side', 'blade_side', 'handle']\n",
    "\n",
    "\n",
    "filtered_unique_labels = [label for label in unique_labels if label in to_keep_table]\n",
    "filtered_unique_labels.append(\"miscellaneous\")\n",
    "print(len(filtered_unique_labels))\n",
    "print(filtered_unique_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create unique integer label pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bolster': 0, 'butt': 1, 'handle': 2, 'handle_side': 3, 'blade': 4, 'guard': 5, 'blade_side': 6, 'miscellaneous': 7}\n"
     ]
    }
   ],
   "source": [
    "unique_integer_label_pairs = {integer: label for label, integer in enumerate(filtered_unique_labels)}\n",
    "# save the dictionary in the data folder, this will be usefull later\n",
    "csv_file_path = target_dir / Path('all_unique_integer_label_pairs.csv')\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Written Out Label', 'Integer Label'])\n",
    "    for label, integer in unique_integer_label_pairs.items():\n",
    "        writer.writerow([label, integer])\n",
    "# pd.DataFrame([unique_integer_label_pairs]).to_csv(\"all_unique_integer_label_pairs.csv\")\n",
    "print(unique_integer_label_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create a new labels file for each sample, based on unique_integer_label_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data(data, flat_dict=None):\n",
    "    \"\"\"\n",
    "    Flattens a nested JSON structure into a dictionary for easy lookup.\n",
    "\n",
    "    :param data: List of dictionaries representing JSON data.\n",
    "    :param flat_dict: A dictionary to store the flattened data.\n",
    "    :return: A dictionary with IDs as keys and corresponding names as values.\n",
    "    \"\"\"\n",
    "    if flat_dict is None:\n",
    "        flat_dict = {}\n",
    "\n",
    "    for item in data:\n",
    "        id = item.get('id')\n",
    "        if id is not None:\n",
    "            flat_dict[id] = item.get('name', 'Name not found')\n",
    "        if 'children' in item:\n",
    "            flatten_data(item['children'], flat_dict)\n",
    "    \n",
    "    return flat_dict\n",
    "\n",
    "for subdirectory in target_dir.iterdir():\n",
    "    if not subdirectory.is_dir():\n",
    "        continue  # Skip if it's not a directory\n",
    "    # Efficiently load labels\n",
    "    label_path = subdirectory / 'point_sample/label-10000.txt'\n",
    "    labels = label_path.read_text().splitlines()\n",
    "    labels = [int(label) for label in labels if label.isdigit()]\n",
    "    \n",
    "    # Load results and flatten them\n",
    "    result_path = subdirectory / 'result.json'\n",
    "    with result_path.open() as file:\n",
    "        results = json.load(file)\n",
    "    flattened_results = flatten_data(results)  # Assuming this is an optimized function\n",
    "\n",
    "    new_labels = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        target_label = flattened_results.get(label, None)\n",
    "        if target_label in unique_integer_label_pairs:\n",
    "            new_labels.append([idx, unique_integer_label_pairs[target_label], target_label])\n",
    "        else:\n",
    "            misc_label = unique_integer_label_pairs[\"miscellaneous\"]\n",
    "            new_labels.append([idx, misc_label, \"miscellaneous\"])\n",
    "            cnt += 1\n",
    "\n",
    "    # Write to CSV file\n",
    "    csv_file_path = subdirectory / 'point_sample/unique_labels.csv'\n",
    "    with csv_file_path.open('w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Point', 'Integer Label', 'Written Out Label'])\n",
    "        writer.writerows(new_labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
