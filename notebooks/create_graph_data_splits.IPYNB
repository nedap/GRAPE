{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a fair data proportions experiment, we need to construct the k folds of the Graph dataset beforehand. We will do this here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/toy-problem\n"
     ]
    }
   ],
   "source": [
    "### SET PATH TO BE ROOT ###\n",
    "\n",
    "import os\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Move one directory up\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "# Change the working directory\n",
    "os.chdir(parent_dir)\n",
    "# Verify the change\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from easydict import EasyDict\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from torch_geometric.loader import DataLoader as GeomDataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from datasets.pytorch import GraphDataset\n",
    "from datasets.pytorch_lightning import GNNDataModule\n",
    "from utils.config import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the below code will output something like:\n",
    "\n",
    "2024-06-13 10:34:17,478 - GraphData - INFO - [DATASET] 5159 instances were loaded\n",
    "\n",
    "This can be ignored, because we acces the \"full_dataset\" below, not the splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 17:03:53,111 - GraphData - INFO - [DATASET] 80 instances were loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SPLIT: 56 train, 16 val, 8 test samples\n",
      "Fold 0 saved\n",
      "Fold 1 saved\n",
      "Fold 2 saved\n",
      "Fold 3 saved\n",
      "Fold 4 saved\n",
      "Test data saved\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(config='cfgs/train_gnn_caesar.yaml')\n",
    "cfg = get_cfg(args=args, logger=None)\n",
    "cfg.dataset.train.return_raw_data = True\n",
    "\n",
    "# init data module\n",
    "data_module = GNNDataModule(cfg=cfg, args=None)\n",
    "full_dataset = data_module.full_dataset\n",
    "\n",
    "# make a 90% train+val and 10% test split\n",
    "train_indices, test_indices = train_test_split(list(range(len(full_dataset))), test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# make a 5 folds for \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# create 5 folds, then save each fold as graph_fold_x\n",
    "fold = 0\n",
    "for train_idx, val_idx in kf.split(train_dataset):\n",
    "    save_dir = Path(f\"/srv/healthcare/datascience/data/GRAPE/caesar_occluded/folds/fold_{fold}\")\n",
    "    # save_dir = Path(f\"/srv/healthcare/datascience/data/GRAPE/table/folds/fold_{fold}\")\n",
    "    # save_dir = Path(f\"/srv/healthcare/datascience/data/GRAPE/table_occluded/folds/fold_{fold}\")\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_fold = Subset(train_dataset, train_idx)\n",
    "    val_fold = Subset(train_dataset, val_idx)\n",
    "    \n",
    "    # save training split\n",
    "    for s, idx in enumerate(train_idx):\n",
    "        sample = full_dataset[idx]     \n",
    "        sample_folder = save_dir / 'training' / f\"{s}/\"\n",
    "        sample_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        nodes = sample['nodes']\n",
    "        edges = sample['edges']\n",
    "\n",
    "        # Save the sample\n",
    "        np.save(sample_folder / 'nodes.npy', nodes)\n",
    "        np.save(sample_folder / 'hierarchy_edges.npy', edges)\n",
    "\n",
    "    # save test split\n",
    "    for s, idx in enumerate(val_idx):\n",
    "        sample = full_dataset[idx]     \n",
    "        sample_folder = save_dir / 'validation' / f\"{s}/\"\n",
    "        sample_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        nodes = sample['nodes']\n",
    "        edges = sample['edges']\n",
    "\n",
    "        # Save the sample\n",
    "        np.save(sample_folder / 'nodes.npy', nodes)\n",
    "        np.save(sample_folder / 'hierarchy_edges.npy', edges)\n",
    "\n",
    "    print(f\"Fold {fold} saved\")\n",
    "    fold += 1\n",
    "\n",
    "# Save test data separately\n",
    "test_save_dir = Path(\"/srv/healthcare/datascience/data/GRAPE/caesar_occluded/test\")\n",
    "\n",
    "# test_save_dir = Path(\"/srv/healthcare/datascience/data/GRAPE/table/test\")\n",
    "# test_save_dir = Path(\"/srv/healthcare/datascience/data/GRAPE/table_occluded/test\")\n",
    "\n",
    "test_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for s, idx in enumerate(test_indices):\n",
    "    sample = full_dataset[idx]\n",
    "    sample_folder = test_save_dir / f\"{s}\"\n",
    "    sample_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    nodes = sample['nodes']\n",
    "    edges = sample['edges']\n",
    "\n",
    "    # Save the sample\n",
    "    np.save(sample_folder / 'nodes.npy', nodes)\n",
    "    np.save(sample_folder / 'hierarchy_edges.npy', edges)\n",
    "\n",
    "print(\"Test data saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
